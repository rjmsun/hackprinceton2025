# ğŸ—ï¸ EVE Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER                                 â”‚
â”‚                    (Browser/Microphone)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ HTTP/WebSocket
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FRONTEND (Port 3000)                       â”‚
â”‚                     Next.js + React                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Components:                                          â”‚  â”‚
â”‚  â”‚  â€¢ RecordingPanel    (audio capture)                 â”‚  â”‚
â”‚  â”‚  â€¢ TasksPanel        (extracted tasks UI)            â”‚  â”‚
â”‚  â”‚  â€¢ SummaryPanel      (meeting summary)               â”‚  â”‚
â”‚  â”‚  â€¢ Dashboard         (analytics)                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ REST API / WebSocket
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND (Port 8000)                        â”‚
â”‚                        FastAPI                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Routes (main.py):                               â”‚  â”‚
â”‚  â”‚  â€¢ POST /transcribe/file                             â”‚  â”‚
â”‚  â”‚  â€¢ POST /process/transcript                          â”‚  â”‚
â”‚  â”‚  â€¢ POST /calendar/schedule                           â”‚  â”‚
â”‚  â”‚  â€¢ POST /voice/summary                               â”‚  â”‚
â”‚  â”‚  â€¢ WS /ws/realtime                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         SERVICE LAYER   â”‚                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚              â”‚              â”‚
           â–¼              â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ OpenAI API  â”‚ â”‚Anthropic APIâ”‚ â”‚ElevenLabs   â”‚
    â”‚             â”‚ â”‚             â”‚ â”‚   API       â”‚
    â”‚ â€¢ Whisper   â”‚ â”‚ â€¢ Claude    â”‚ â”‚ â€¢ TTS       â”‚
    â”‚ â€¢ GPT-4o    â”‚ â”‚   3.5       â”‚ â”‚             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚              â”‚              â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                             â”‚
           â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Google     â”‚             â”‚  Amplitude   â”‚
    â”‚  Calendar   â”‚             â”‚  (Optional)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow

### 1. Audio Recording/Upload

```
User clicks "Record" or uploads file
    â”‚
    â–¼
[RecordingPanel.tsx]
    â”‚
    â”œâ”€â–º MediaRecorder API (for live recording)
    â”‚   or
    â””â”€â–º File input (for uploads)
    â”‚
    â–¼
POST /transcribe/file
    â”‚
    â–¼
[transcription.py]
    â”‚
    â”œâ”€â–º OpenAI Whisper API
    â”‚       â”‚
    â”‚       â–¼
    â”‚   Audio â†’ Text transcript
    â”‚
    â””â”€â–º Returns transcript to frontend
```

### 2. Transcript Processing

```
Transcript received
    â”‚
    â–¼
POST /process/transcript
    â”‚
    â–¼
[reasoning.py]
    â”‚
    â”œâ”€â–º Step 1: clean_transcript()
    â”‚   â”‚
    â”‚   â”œâ”€â–º GPT-4o API
    â”‚   â””â”€â–º Returns: { sections: [...] }
    â”‚
    â”œâ”€â–º Step 2: extract_tasks()
    â”‚   â”‚
    â”‚   â”œâ”€â–º Claude 3.5 API
    â”‚   â””â”€â–º Returns: { tasks: [...] }
    â”‚
    â””â”€â–º Step 3: generate_summary()
        â”‚
        â”œâ”€â–º GPT-4o API
        â””â”€â–º Returns: { short_summary, detailed_summary }
    â”‚
    â–¼
Returns all to frontend
```

### 3. Calendar Scheduling

```
User selects tasks
    â”‚
    â–¼
POST /calendar/schedule
    â”‚
    â–¼
[reasoning.py] create_event_suggestion()
    â”‚
    â”œâ”€â–º GPT-4o converts task â†’ calendar event
    â”‚
    â–¼
[calendar_service.py] create_event()
    â”‚
    â”œâ”€â–º Google Calendar API
    â””â”€â–º Creates event
    â”‚
    â–¼
Returns event confirmation
```

### 4. Voice Summary

```
Summary generated
    â”‚
    â–¼
POST /voice/summary
    â”‚
    â–¼
[reasoning.py] generate_voice_summary()
    â”‚
    â”œâ”€â–º GPT-4o creates spoken text
    â”‚
    â–¼
[tts.py] text_to_speech()
    â”‚
    â”œâ”€â–º ElevenLabs API
    â””â”€â–º Returns audio bytes
    â”‚
    â–¼
Browser plays audio
```

---

## API Key Flow

```
1. User creates .env file:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ OPENAI_API_KEY=sk-proj-... â”‚
   â”‚ ANTHROPIC_API_KEY=sk-ant...â”‚
   â”‚ ELEVENLABS_API_KEY=...     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Backend loads on startup:
   [main.py]
   â”‚
   â”œâ”€â–º load_dotenv() â†’ loads .env
   â”‚
   â”œâ”€â–º os.getenv("OPENAI_API_KEY")
   â”‚
   â””â”€â–º Initializes services with keys

3. Services use keys:
   [transcription.py]
       openai.OpenAI(api_key=key)
   
   [reasoning.py]
       openai.OpenAI(api_key=openai_key)
       anthropic.Anthropic(api_key=anthropic_key)
   
   [tts.py]
       headers = {"xi-api-key": elevenlabs_key}
```

---

## File Structure with Purpose

```
hackprinceton2025/
â”‚
â”œâ”€â”€ .env                          â† YOUR API KEYS GO HERE
â”œâ”€â”€ env.example                   â† Template for .env
â”‚
â”œâ”€â”€ start.sh                      â† Run this to start EVE
â”œâ”€â”€ install.sh                    â† Run this first (install deps)
â”œâ”€â”€ test-api-keys.sh              â† Verify API keys work
â”‚
â”œâ”€â”€ backend/                      â† Python FastAPI server
â”‚   â”œâ”€â”€ main.py                   â† API routes + service init
â”‚   â”œâ”€â”€ run.py                    â† Alternative entry point
â”‚   â”œâ”€â”€ requirements.txt          â† Python dependencies
â”‚   â”‚
â”‚   â””â”€â”€ services/                 â† AI integrations
â”‚       â”œâ”€â”€ transcription.py      â† OpenAI Whisper
â”‚       â”œâ”€â”€ reasoning.py          â† GPT-4o + Claude 3.5
â”‚       â”œâ”€â”€ tts.py                â† ElevenLabs TTS
â”‚       â”œâ”€â”€ calendar_service.py   â† Google Calendar
â”‚       â””â”€â”€ analytics.py          â† Amplitude (optional)
â”‚
â””â”€â”€ frontend/                     â† Next.js React app
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ page.tsx              â† Main page
    â”‚   â”œâ”€â”€ layout.tsx            â† App layout
    â”‚   â””â”€â”€ globals.css           â† Styles
    â”‚
    â””â”€â”€ components/
        â”œâ”€â”€ RecordingPanel.tsx    â† Audio recording UI
        â”œâ”€â”€ TasksPanel.tsx        â† Tasks display
        â”œâ”€â”€ SummaryPanel.tsx      â† Summary + voice
        â””â”€â”€ Dashboard.tsx         â† Analytics cards
```

---

## Service Initialization

```python
# backend/main.py

from dotenv import load_dotenv
load_dotenv()  # Loads .env into environment

# Initialize services with API keys
transcription_service = TranscriptionService(
    api_key=os.getenv("OPENAI_API_KEY")
)

reasoning_service = ReasoningService(
    openai_key=os.getenv("OPENAI_API_KEY"),
    anthropic_key=os.getenv("ANTHROPIC_API_KEY")
)

calendar_service = CalendarService(
    client_id=os.getenv("GOOGLE_CLIENT_ID"),
    client_secret=os.getenv("GOOGLE_CLIENT_SECRET")
)

tts_service = TTSService(
    api_key=os.getenv("ELEVENLABS_API_KEY")
)

analytics_service = AnalyticsService(
    api_key=os.getenv("AMPLITUDE_API_KEY")
)
```

---

## Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **Frontend** | Next.js 14 | React framework |
| | React 18 | UI components |
| | TypeScript | Type safety |
| | Tailwind CSS | Styling |
| | Axios | HTTP client |
| **Backend** | FastAPI | API framework |
| | Python 3.9+ | Runtime |
| | Uvicorn | ASGI server |
| | python-dotenv | Env loading |
| **AI APIs** | OpenAI Whisper | Transcription |
| | OpenAI GPT-4o | Reasoning |
| | Anthropic Claude 3.5 | Task extraction |
| | ElevenLabs | Voice synthesis |
| **Integrations** | Google Calendar API | Scheduling |
| | Amplitude API | Analytics |

---

## Sponsor API Usage

| Sponsor | API | Used In | Purpose |
|---------|-----|---------|---------|
| **OpenAI** | Whisper | `transcription.py` | Audio â†’ Text |
| | GPT-4o | `reasoning.py` | Summarization, scheduling |
| **Anthropic** | Claude 3.5 | `reasoning.py` | Task extraction |
| **ElevenLabs** | TTS | `tts.py` | Voice summaries |
| **Google** | Calendar API | `calendar_service.py` | Auto-scheduling |
| **MLH** | Amplitude | `analytics.py` | Usage tracking |

---

## Adding New Features

### Add a new AI service:

1. Create `backend/services/new_service.py`:
```python
class NewService:
    def __init__(self, api_key: str):
        self.api_key = api_key
    
    async def do_something(self, input_data):
        # API call here
        return result
```

2. Initialize in `backend/main.py`:
```python
new_service = NewService(api_key=os.getenv("NEW_API_KEY"))
```

3. Add route:
```python
@app.post("/new/endpoint")
async def new_endpoint(data: Request):
    result = await new_service.do_something(data)
    return result
```

4. Call from frontend:
```typescript
const response = await axios.post(`${API_URL}/new/endpoint`, data)
```

---

## Security Notes

âœ… `.env` is in `.gitignore` (never committed)  
âœ… API keys loaded server-side only  
âœ… CORS configured for localhost  
âœ… OAuth tokens stored securely  

For production:
- Use environment variables (not `.env` files)
- Enable HTTPS
- Add rate limiting
- Implement auth middleware

---

## Performance

- Audio transcription: ~2-5 seconds per minute
- Task extraction: ~3-7 seconds (depends on length)
- Voice synthesis: ~1-2 seconds per sentence
- Total pipeline: ~10-15 seconds for 2-minute meeting

---

## Debugging

**Backend logs:**
```bash
cd backend
python main.py
# Watch terminal for errors
```

**Frontend logs:**
```bash
cd frontend
npm run dev
# Check browser console
```

**API docs:**
- Backend: http://localhost:8000/docs
- Interactive testing with Swagger UI

---

This architecture is designed to be modular, scalable, and sponsor-friendly! ğŸš€

