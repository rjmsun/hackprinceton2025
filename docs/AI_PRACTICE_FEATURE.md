# üéØ Practice with AI - Conversational Coaching Feature

## Overview

The **Practice with AI** feature transforms EVE into an interactive conversational coach that speaks to you, listens to your responses, and provides real-time feedback - simulating a natural back-and-forth conversation just like talking to a real coach or tutor.

## üåü Key Features

### Natural Conversation Flow
- **AI speaks first**: Using ElevenLabs TTS, the AI greets you and sets up the practice session
- **You respond via voice**: Click the mic button, speak your response, and the AI transcribes it
- **Continuous dialogue**: The conversation continues naturally based on your responses
- **Context-aware feedback**: AI remembers the conversation history and builds on previous exchanges

### Three Modes

#### 1. üé§ Interview Practice Mode
- AI identifies weak spots from your original interview transcript
- Asks you interview questions conversationally
- Provides encouraging, specific feedback after each answer
- Helps you practice better responses to tricky questions
- Uses "you" and "I" naturally (e.g., "I noticed you seemed uncertain about...")

#### 2. üìö Lecture Study Mode  
- AI acts as a patient tutor
- Tests your understanding with conceptual questions
- Explains concepts you're confused about
- Provides examples and clarifications
- Builds on your answers - acknowledges what's right, adds what's missing

#### 3. ‚òï Networking Practice Mode
- AI plays the role of a networking coach
- Practices follow-up questions and conversation skills
- Keeps it casual and encouraging
- Helps you sound more natural and engaging

## üöÄ How to Use

### Step 1: Record & Analyze
1. Record or upload an audio file (interview, lecture, or coffee chat)
2. Select the appropriate **Context** (Interview, Lecture, or Coffee Chat)
3. Click **"‚ú® Generate Smart Analysis & Tasks"**
4. Wait for the analysis to complete

### Step 2: Start Practice Session
1. After analysis completes, you'll see the **"üéØ Practice with AI"** button
2. Click it to see the feature description
3. Click **"Start Practice Session"** to begin
4. The AI will greet you and explain what you'll work on (audio will auto-play)

### Step 3: Have a Conversation
1. **Listen**: The AI speaks to you via high-quality voice synthesis
2. **Record your response**: Click the green "Record Response" button
3. **Speak naturally**: Answer the question or respond to the AI
4. **Stop recording**: Click "Stop Recording" when done
5. **Get feedback**: AI transcribes your response, analyzes it, and speaks back to you
6. **Continue**: The conversation flows naturally - keep going as long as you want!

### Step 4: Review & Reset
- **Replay messages**: Click the speaker icon on any AI message to hear it again
- **See your conversation**: All messages are displayed in a chat-style interface
- **Reset session**: Click "Reset" to start over with a fresh conversation

## üé® What Makes This Different

### vs. Traditional "Speak Summary"
- **OLD**: Just reads out a summary of tasks (one-way)
- **NEW**: Interactive back-and-forth conversation with feedback (two-way)

### vs. Scenario-Based Practice
- **OLD**: Pick from predefined scenarios, answer, get feedback (rigid)
- **NEW**: Free-flowing conversation that adapts to your responses (natural)

### Chess.com-Style Analysis
Just like chess.com identifies "blunders" and "brilliant moves", our AI:
- Identifies weak points in your original performance
- Lets you "replay" those moments
- Gives you immediate feedback on your improved response
- Tracks your progress through the conversation

## üõ†Ô∏è Technical Implementation

### Backend (`/conversation/start`)
```python
# Starts a new practice session
POST /conversation/start
{
  "transcript": "original transcript text",
  "context": "interview" | "lecture" | "coffee_chat",
  "coaching_insights": {...}  # optional
}

# Returns:
{
  "session": {
    "session_type": "interview_practice",
    "opening_message": "Hey! Ready to practice...",
    "opening_audio": "base64_encoded_mp3",
    "conversation_history": [...],
    "context_data": {...}
  }
}
```

### Backend (`/conversation/continue`)
```python
# Continues the conversation
POST /conversation/continue
{
  "user_message": "transcribed user response",
  "conversation_history": [...],
  "context_data": {...},
  "session_type": "interview_practice"
}

# Returns:
{
  "assistant_message": "Great! I noticed you...",
  "audio": "base64_encoded_mp3",
  "conversation_history": [...]  # updated
}
```

### Frontend Component
- **`AIPracticePanel.tsx`**: Main conversational interface
- **State management**: Tracks messages, session data, recording status
- **Audio handling**: Plays base64-encoded audio from responses
- **Real-time transcription**: Uses existing OpenAI Whisper integration
- **Chat UI**: Message bubbles with timestamps and replay buttons

## üîß Configuration

### Required API Keys
```env
OPENAI_API_KEY=sk-...          # For GPT-4o conversation + Whisper transcription
ELEVENLABS_API_KEY=...         # For text-to-speech
```

### Models Used
- **Conversation**: GPT-4o (for natural, context-aware responses)
- **Session setup**: GPT-4o-mini (for initial greetings)
- **Transcription**: Whisper-1 (for user speech-to-text)
- **TTS**: ElevenLabs Turbo v2.5 (for AI speech)

## üìä User Flow Example

### Interview Practice Example:
```
1. User uploads interview recording
2. Clicks "Generate Smart Analysis"
3. System identifies: "You seemed uncertain when asked about project experience"
4. User clicks "Practice with AI"
5. AI speaks: "Hey! I noticed you had some trouble with the project question. 
   Want to practice that one together?"
6. User clicks mic, responds: "Yes, I'd like to practice that"
7. AI speaks: "Great! So tell me about a challenging project you worked on"
8. User records improved answer
9. AI provides feedback: "Much better! I liked how you started with the context. 
   One thing to add: mention the impact of your work"
10. Conversation continues naturally...
```

## üéØ Success Metrics

The feature is successful when:
- ‚úÖ Users can have 5+ message exchanges in one session
- ‚úÖ Audio plays automatically without errors
- ‚úÖ Transcription accuracy is high (validated by Whisper + GPT-4o)
- ‚úÖ Feedback feels conversational, not robotic
- ‚úÖ Users report feeling more prepared after practice

## üöß Future Enhancements

### Potential additions:
1. **Multi-turn scenarios**: AI can simulate a full mock interview (10+ questions)
2. **Progress tracking**: Save practice sessions, show improvement over time
3. **Personality selection**: Choose AI coach personality (encouraging, strict, casual)
4. **Video support**: Practice with video for body language feedback
5. **Real-time feedback**: Show sentiment/confidence as user speaks
6. **Collaborative mode**: Practice with multiple AI interviewers

## üêõ Troubleshooting

### Audio doesn't play
- Check that ELEVENLABS_API_KEY is set
- Verify browser allows autoplay (some browsers block it)
- Check browser console for errors

### Microphone doesn't work
- Allow microphone permissions in browser
- Check that no other app is using the mic
- Try refreshing the page

### Transcription errors
- Speak clearly and at moderate pace
- Reduce background noise
- Check OPENAI_API_KEY is valid

### AI responses are too generic
- Make sure original transcript has good content
- Ensure coaching insights were generated properly
- Try resetting and starting a new session

## üìö Related Documentation

- [TESTING_NEW_FEATURES.md](./TESTING_NEW_FEATURES.md) - How to test the feature
- [HOW_IT_WORKS.md](./HOW_IT_WORKS.md) - Overall system architecture
- [FINAL_FEATURES.md](./FINAL_FEATURES.md) - Complete feature list

## üéâ Conclusion

The **Practice with AI** feature is the culmination of multiple APIs working together seamlessly:
- **OpenAI Whisper** for transcription
- **OpenAI GPT-4o** for intelligent conversation
- **ElevenLabs** for natural voice synthesis
- **React + TypeScript** for smooth UI/UX

This creates a truly immersive practice experience that feels like talking to a real coach, not just an automated system.

**Built with ‚ù§Ô∏è for HackPrinceton 2025**

